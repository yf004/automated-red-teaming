{
    "sourceFile": "main.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1765741921039,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1765747795504,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -431,14 +431,8 @@\n     print(f\"TARGET URL: {url}\")\r\n     print(f\"GOAL: {goal}\")\r\n     print(f\"{'='*80}\\n\")\r\n \r\n-    # ============================================================================\r\n-    # STEP 1: Generate scanner tool inputs\r\n-    # ============================================================================\r\n-    print(f\"\\n{'='*80}\")\r\n-    print(\"STEP 1: GENERATING SCANNER TOOL INPUTS\")\r\n-    print(f\"{'='*80}\\n\")\r\n     \r\n     scanner_input_state = await scanner_input_workflow.ainvoke(\r\n         {\r\n             \"messages\": [HumanMessage(content=f\"Target URL: {url}\\nGoal: {goal}\")],\r\n@@ -467,24 +461,13 @@\n     if not scanner_inputs:\r\n         print(\"ERROR: Scanner input generator did not produce valid inputs\")\r\n         sys.exit(1)\r\n     \r\n-    # ============================================================================\r\n-    # STEP 2: Run scanner tool EXTERNALLY (outside agent framework)\r\n-    # ============================================================================\r\n-    print(f\"\\n{'='*80}\")\r\n-    print(\"STEP 2: RUNNING SCANNER TOOL (EXTERNAL)\")\r\n-    print(f\"{'='*80}\\n\")\r\n+\r\n     \r\n     initial_scan_report = await run_scanner_tool(scanner_inputs)\r\n+\r\n     \r\n-    # ============================================================================\r\n-    # STEP 3: Run pentest loop with scan report\r\n-    # ============================================================================\r\n-    print(f\"\\n{'='*80}\")\r\n-    print(\"STEP 3: RUNNING PENTEST LOOP\")\r\n-    print(f\"{'='*80}\\n\")\r\n-    \r\n     flag = True\r\n     while flag:\r\n         try:\r\n             pentest_result = await pentest_agents.ainvoke(\r\n"
                }
            ],
            "date": 1765741921039,
            "name": "Commit-0",
            "content": "import sys\r\nfrom typing import TypedDict, Union, Optional, Any, List\r\nimport json\r\nimport asyncio\r\nimport warnings\r\nimport nest_asyncio\r\n\r\nfrom langchain_ollama.chat_models import ChatOllama\r\nfrom agents.prompts import (\r\n    scanner_input_generator_prompt,  # NEW: generates tool inputs instead of running tools\r\n    planner_agent_prompt, \r\n    attacker_agent_prompt, \r\n    critic_agent_prompt, \r\n    exploit_evaluator_agent_prompt, \r\n    report_writer_agent_prompt, \r\n    supervisor_agent_prompt\r\n)\r\nfrom agents.outputs import(\r\n    ExploitEvaluatorOutput, \r\n    AttackerOutput, \r\n    PlannerOutput, \r\n    CriticOutput,\r\n    ScannerInputOutput,  # NEW: for scanner tool inputs\r\n    call_ollama_with_json\r\n)\r\nfrom langchain_core.exceptions import OutputParserException\r\nfrom langgraph.graph import END, START, StateGraph\r\nfrom langgraph.prebuilt import create_react_agent\r\nfrom langgraph_supervisor import create_supervisor\r\nfrom pydantic import Field\r\nfrom langchain_core.messages import HumanMessage, AIMessage\r\n\r\nfrom tools.all_tools import (\r\n    PentestState,\r\n    attacker_tools,\r\n    get_attempts,\r\n    planner_tools,\r\n    report_writer_tools,\r\n    scanner_input_tools,  # NEW: tools for generating scanner inputs (no actual scanner)\r\n)\r\n\r\nnest_asyncio.apply()\r\nwarnings.filterwarnings(\"ignore\", category=ResourceWarning)\r\n\r\nif len(sys.argv) < 3:\r\n    print(\"Usage: python main.py <url> <model>\")\r\n    sys.exit(1)\r\n\r\n\r\nasync def run_scanner_tool(scanner_inputs: dict) -> str:\r\n    \"\"\"\r\n    Run the NoSQL scanner tool OUTSIDE the agentic framework.\r\n    This function executes the actual scanner with the provided inputs.\r\n    \r\n    Args:\r\n        scanner_inputs: Dictionary containing tool parameters from the agent\r\n        \r\n    Returns:\r\n        The scanner report as a string\r\n    \"\"\"\r\n    from tools.scanning_tool.nosql_scanner import ScanForNoSQLITool\r\n    \r\n    print(f\"\\n{'='*80}\")\r\n    print(\"EXECUTING NOSQL SCANNER TOOL (OUTSIDE AGENT FRAMEWORK)\")\r\n    print(f\"{'='*80}\")\r\n    print(f\"Scanner Inputs: {json.dumps(scanner_inputs, indent=2)}\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    # Initialize the scanner tool\r\n    scanner_tool = ScanForNoSQLITool()\r\n    \r\n    # Run the scanner with the provided inputs\r\n    # This may take some time, which is why we run it outside the agent\r\n    scan_report = await scanner_tool.arun(scanner_inputs)\r\n    \r\n    print(f\"\\n{'='*80}\")\r\n    print(\"SCANNER TOOL EXECUTION COMPLETE\")\r\n    print(f\"Report length: {len(scan_report)} characters\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    return scan_report\r\n\r\n\r\nasync def main():\r\n    MODEL = sys.argv[2]\r\n\r\n    # ============================================================================\r\n    # PHASE 1: SCANNER INPUT GENERATION\r\n    # ============================================================================\r\n    async def scanner_input_generator(state: PentestState):\r\n        \"\"\"\r\n        Agent that generates the INPUTS for the NoSQL scanner tool,\r\n        but does NOT execute the tool itself.\r\n        \"\"\"\r\n        scanner_input_agent = create_react_agent(\r\n            model=ChatOllama(model=MODEL, temperature=0),\r\n            prompt=scanner_input_generator_prompt,\r\n            name=\"scanner_input_generator\",\r\n            tools=await scanner_input_tools(),  # Tools that help explore, but no actual scanner\r\n            state_schema=PentestState,\r\n            debug=True,\r\n        )\r\n        \r\n        resp = await scanner_input_agent.ainvoke(state)\r\n        \r\n        # The agent's final output should describe what inputs to pass to the scanner\r\n        raw_output = resp[\"messages\"][-1].content\r\n        \r\n        print(f\"\\n{'='*80}\")\r\n        print(\"SCANNER INPUT GENERATOR OUTPUT\")\r\n        print(f\"{'='*80}\")\r\n        print(f\"Output: {raw_output[:500]}...\")\r\n        print(f\"{'='*80}\\n\")\r\n        \r\n        return {\r\n            \"messages\": [resp[\"messages\"][-1]],\r\n            \"raw_scanner_input\": raw_output,\r\n        }\r\n    \r\n    async def scanner_input_structurer(state: PentestState):\r\n        \"\"\"Structure scanner input generator output using Ollama JSON mode.\"\"\"\r\n        content = state[\"raw_scanner_input\"]\r\n        \r\n        try:\r\n            result = await call_ollama_with_json(MODEL, content, ScannerInputOutput)\r\n            \r\n            # Extract the structured scanner inputs\r\n            scanner_inputs = result.get(\"scanner_tool_inputs\", {})\r\n            \r\n            return {\r\n                \"scanner_tool_inputs\": scanner_inputs,\r\n                \"raw_scanner_input\": None,\r\n            }\r\n        except Exception as e:\r\n            print(f\"\\n=== ERROR IN SCANNER_INPUT_STRUCTURER ===\")\r\n            print(f\"Error: {e}\")\r\n            print(f\"Raw content length: {len(content)}\")\r\n            print(f\"Raw content preview: {content[:500]}...\")\r\n            print(f\"==========================================\\n\")\r\n            raise\r\n\r\n    # ============================================================================\r\n    # PHASE 2: PENTEST AGENTS (NO SCANNER)\r\n    # ============================================================================\r\n    async def planner(state: PentestState):\r\n        \"\"\"Planner agent returns raw natural language output.\"\"\"\r\n        planner_agent = create_react_agent(\r\n            model=ChatOllama(model=MODEL, temperature=0, verbose=False),\r\n            prompt=planner_agent_prompt,\r\n            name=\"planner_agent\",\r\n            tools=await planner_tools(),\r\n            state_schema=PentestState,\r\n            debug=True,\r\n        )\r\n        \r\n        resp = await planner_agent.ainvoke(state)\r\n        \r\n        return {\r\n            \"messages\": [resp[\"messages\"][-1]],\r\n            \"raw_planner_output\": resp[\"messages\"][-1].content,\r\n        }\r\n    \r\n    async def planner_structurer(state: PentestState):\r\n        \"\"\"Structure planner output using Ollama JSON mode.\"\"\"\r\n        content = state[\"raw_planner_output\"]\r\n        \r\n        try:\r\n            result = await call_ollama_with_json(MODEL, content, PlannerOutput)\r\n            \r\n            final_output = result.get(\"final_output\", {})\r\n            \r\n            if isinstance(final_output, dict):\r\n                final_output = [final_output]\r\n            \r\n            if not isinstance(final_output, list):\r\n                raise ValueError(f\"Planner structurer did not return payloads in a valid list format. Got type: {type(final_output)}\")\r\n                        \r\n            return {\r\n                \"payloads\": final_output,\r\n                \"raw_planner_output\": None,\r\n            }\r\n        except Exception as e:\r\n            print(f\"\\n=== ERROR IN PLANNER_STRUCTURER ===\")\r\n            print(f\"Error: {e}\")\r\n            print(f\"Raw content length: {len(content)}\")\r\n            print(f\"Raw content preview: {content[:500]}...\")\r\n            print(f\"====================================\\n\")\r\n            raise\r\n\r\n    async def attacker(state: PentestState):\r\n        \"\"\"Attacker agent returns raw natural language output (no structured output).\"\"\"\r\n        attacker_agent = create_react_agent(\r\n            model=ChatOllama(model=MODEL, temperature=0, verbose=False),\r\n            prompt=attacker_agent_prompt,\r\n            name=\"attacker_agent\",\r\n            tools=attacker_tools(),\r\n            state_schema=PentestState,\r\n            debug=True,\r\n        )\r\n        \r\n        resp = await attacker_agent.ainvoke(state)\r\n        \r\n        return {\r\n            \"messages\": [resp[\"messages\"][-1]],\r\n            \"raw_attacker_output\": resp[\"messages\"][-1].content,\r\n            \"attempts\": state[\"attempts\"],\r\n        }\r\n    \r\n    async def attacker_structurer(state: PentestState):\r\n        \"\"\"Structure attacker output using Ollama JSON mode.\"\"\"\r\n        content = state[\"raw_attacker_output\"]\r\n        \r\n        try:\r\n            result = await call_ollama_with_json(MODEL, content, AttackerOutput)\r\n            \r\n            if \"final_output\" not in result or not isinstance(result[\"final_output\"], list):\r\n                raise ValueError(f\"Attacker structurer did not return valid attempts. Got keys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}\")\r\n            \r\n            new_attempts = result[\"final_output\"]\r\n            \r\n            return {\r\n                \"attempts\": state[\"attempts\"] + new_attempts,\r\n                \"raw_attacker_output\": None,\r\n            }\r\n        except Exception as e:\r\n            print(f\"\\n=== ERROR IN ATTACKER_STRUCTURER ===\")\r\n            print(f\"Error: {e}\")\r\n            print(f\"Raw content length: {len(content)}\")\r\n            print(f\"Raw content preview: {content[:500]}...\")\r\n            print(f\"=====================================\\n\")\r\n            raise\r\n\r\n    async def critic(state: PentestState):\r\n        \"\"\"Critic agent returns raw natural language output.\"\"\"\r\n        critic_agent = create_react_agent(\r\n            model=ChatOllama(model=MODEL, temperature=0, verbose=False),\r\n            prompt=critic_agent_prompt,\r\n            name=\"critic_agent\",\r\n            tools=await planner_tools(),\r\n            state_schema=PentestState,\r\n            debug=True,\r\n        )\r\n        \r\n        resp = await critic_agent.ainvoke(state)\r\n        \r\n        return {\r\n            \"messages\": [resp[\"messages\"][-1]],\r\n            \"raw_critic_output\": resp[\"messages\"][-1].content,\r\n        }\r\n    \r\n    async def critic_structurer(state: PentestState):\r\n        \"\"\"Structure critic output using Ollama JSON mode.\"\"\"\r\n        content = state[\"raw_critic_output\"]\r\n        \r\n        try:\r\n            result = await call_ollama_with_json(MODEL, content, CriticOutput)\r\n            \r\n            if \"final_output\" in result:\r\n                final_output = result[\"final_output\"]\r\n            elif \"analysis\" in result and \"recommendation\" in result:\r\n                final_output = result\r\n            else:\r\n                raise ValueError(f\"Critic structurer: unexpected structure. Keys: {list(result.keys())}\")\r\n            \r\n            if not isinstance(final_output, dict):\r\n                raise ValueError(f\"Final output is not a dict. Type: {type(final_output)}\")\r\n            \r\n            if \"analysis\" not in final_output:\r\n                raise ValueError(f\"Final output missing 'analysis' key. Keys: {list(final_output.keys())}\")\r\n                \r\n            if \"recommendation\" not in final_output:\r\n                raise ValueError(f\"Final output missing 'recommendation' key. Keys: {list(final_output.keys())}\")\r\n            \r\n            if not isinstance(final_output[\"analysis\"], list):\r\n                final_output[\"analysis\"] = [final_output[\"analysis\"]]\r\n            \r\n            if not isinstance(final_output[\"recommendation\"], dict):\r\n                raise ValueError(f\"Recommendation is not a dict. Type: {type(final_output['recommendation'])}\")\r\n                        \r\n            c = state[\"attempts\"].copy()\r\n            \r\n            for analysis_entry in final_output[\"analysis\"]:\r\n                if not isinstance(analysis_entry, dict):\r\n                    print(f\"âš  Warning: Skipping non-dict analysis entry: {analysis_entry}\")\r\n                    continue\r\n                    \r\n                for attempt_entry in c:\r\n                    if (\r\n                        analysis_entry.get(\"page_url\") == attempt_entry.get(\"page_url\")\r\n                        and analysis_entry.get(\"payloads\") == attempt_entry.get(\"payloads\")\r\n                    ):\r\n                        attempt_entry.update(analysis_entry)\r\n            \r\n            return {\r\n                \"attempts\": c,\r\n                \"recommendation\": final_output[\"recommendation\"],\r\n                \"raw_critic_output\": None,\r\n            }\r\n        except Exception as e:\r\n            print(f\"\\n=== ERROR IN CRITIC_STRUCTURER ===\")\r\n            print(f\"Error: {e}\")\r\n            print(f\"Error type: {type(e).__name__}\")\r\n            print(f\"Raw content length: {len(content)}\")\r\n            print(f\"Raw content preview: {content[:1000]}...\")\r\n            if 'result' in locals():\r\n                print(f\"Parsed result keys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}\")\r\n                if isinstance(result, dict) and len(str(result)) < 2000:\r\n                    print(f\"Full result: {json.dumps(result, indent=2)}\")\r\n            print(f\"===================================\\n\")\r\n            raise\r\n\r\n    async def exploit_evaluator(state: PentestState):\r\n        \"\"\"Exploit evaluator using Ollama JSON mode for structured output.\"\"\"\r\n        prompt = f\"\"\"\r\n{exploit_evaluator_agent_prompt}\r\n\r\n[CURRENT STATE]\r\nAttempts: {state['attempts']}\r\nTries: {state['tries']}\r\nGoal: {state['goal']}\r\n\r\nAnalyze the attempts and decide if the loop should terminate.\r\nNOTE: Do NOT terminate to request re-scanning. The scanner has already run and cannot be called again.\r\n\"\"\"\r\n        \r\n        try:\r\n            result = await call_ollama_with_json(MODEL, prompt, ExploitEvaluatorOutput)\r\n            \r\n            if \"reason\" not in result:\r\n                raise ValueError(\"Exploit Evaluator did not provide a reason for termination\")\r\n            if \"should_terminate\" not in result:\r\n                raise ValueError(\"Exploit Evaluator did not indicate whether to terminate or not\")\r\n\r\n            should_terminate = result[\"should_terminate\"]\r\n            reason = result[\"reason\"]\r\n            \r\n            print(f\"\\n{'='*60}\")\r\n            print(f\"EXPLOIT EVALUATOR DECISION:\")\r\n            print(f\"  Terminate: {should_terminate}\")\r\n            print(f\"  Reason: {reason}\")\r\n            print(f\"  Try #{state['tries'] + 1}\")\r\n            print(f\"{'='*60}\\n\")\r\n\r\n            return {\r\n                \"messages\": [AIMessage(content=str(result))],\r\n                \"should_terminate\": should_terminate,\r\n                \"reason\": reason,\r\n                \"tries\": state[\"tries\"] + 1,\r\n                \"attempts\": [] if should_terminate else state[\"attempts\"],\r\n                \"recommendation\": \"\" if should_terminate else state[\"recommendation\"],\r\n                \"successful_payload\": result.get(\"successful_payload\", {}),\r\n            }\r\n        except Exception as e:\r\n            print(f\"\\n=== ERROR IN EXPLOIT_EVALUATOR ===\")\r\n            print(f\"Error: {e}\")\r\n            print(f\"Prompt length: {len(prompt)}\")\r\n            print(f\"===================================\\n\")\r\n            raise\r\n\r\n    def exploit_evaluator_decision(state: PentestState):\r\n        \"\"\"\r\n        Route decision after exploit evaluator.\r\n        Now only routes between critic and ending (no scanner option).\r\n        \"\"\"\r\n        if state[\"should_terminate\"] or state[\"tries\"] > 10:\r\n            return \"end\"\r\n        else:\r\n            return \"critic_agent\"\r\n\r\n    # ============================================================================\r\n    # PHASE 1 GRAPH: SCANNER INPUT GENERATION\r\n    # ============================================================================\r\n    scanner_input_graph = StateGraph(PentestState)\r\n    scanner_input_graph.add_node(\"scanner_input_generator\", scanner_input_generator)\r\n    scanner_input_graph.add_node(\"scanner_input_structurer\", scanner_input_structurer)\r\n    \r\n    scanner_input_graph.add_edge(START, \"scanner_input_generator\")\r\n    scanner_input_graph.add_edge(\"scanner_input_generator\", \"scanner_input_structurer\")\r\n    scanner_input_graph.add_edge(\"scanner_input_structurer\", END)\r\n    \r\n    scanner_input_workflow = scanner_input_graph.compile()\r\n\r\n    # ============================================================================\r\n    # PHASE 2 GRAPH: PENTEST LOOP (NO SCANNER)\r\n    # ============================================================================\r\n    pentest_subgraph = StateGraph(PentestState)\r\n    pentest_subgraph.add_node(\"planner_agent\", planner)\r\n    pentest_subgraph.add_node(\"planner_structurer\", planner_structurer)\r\n    pentest_subgraph.add_node(\"attacker_agent\", attacker)\r\n    pentest_subgraph.add_node(\"attacker_structurer\", attacker_structurer)\r\n    pentest_subgraph.add_node(\"critic_agent\", critic)\r\n    pentest_subgraph.add_node(\"critic_structurer\", critic_structurer)\r\n    pentest_subgraph.add_node(\"exploit_evaluator_agent\", exploit_evaluator)\r\n\r\n    # Start directly at planner (scanner already ran externally)\r\n    pentest_subgraph.add_edge(START, \"planner_agent\")\r\n    pentest_subgraph.add_edge(\"planner_agent\", \"planner_structurer\")\r\n    pentest_subgraph.add_edge(\"planner_structurer\", \"attacker_agent\")\r\n    pentest_subgraph.add_edge(\"attacker_agent\", \"attacker_structurer\")\r\n    pentest_subgraph.add_edge(\"attacker_structurer\", \"exploit_evaluator_agent\")\r\n    pentest_subgraph.add_conditional_edges(\r\n        \"exploit_evaluator_agent\",\r\n        exploit_evaluator_decision,\r\n        {\"end\": END, \"critic_agent\": \"critic_agent\"},\r\n    )\r\n    pentest_subgraph.add_edge(\"critic_agent\", \"critic_structurer\")\r\n    # Critic goes back to planner, NOT scanner\r\n    pentest_subgraph.add_edge(\"critic_structurer\", \"planner_agent\")\r\n    \r\n    pentest_agents = pentest_subgraph.compile(name=\"pentest_agents\")\r\n\r\n    # ============================================================================\r\n    # PHASE 3: REPORT WRITER\r\n    # ============================================================================\r\n    report_writer_agent = create_react_agent(\r\n        model=ChatOllama(model=MODEL, temperature=0.3),\r\n        prompt=report_writer_agent_prompt,\r\n        name=\"report_writer_agent\",\r\n        tools=report_writer_tools(),\r\n        state_schema=PentestState,\r\n        debug=True,\r\n    )\r\n\r\n    # ============================================================================\r\n    # MAIN EXECUTION FLOW\r\n    # ============================================================================\r\n    url = sys.argv[1]\r\n    goal = input('Input goal: ')\r\n    \r\n    print(f\"\\n{'='*80}\")\r\n    print(f\"TARGET URL: {url}\")\r\n    print(f\"GOAL: {goal}\")\r\n    print(f\"{'='*80}\\n\")\r\n\r\n    # ============================================================================\r\n    # STEP 1: Generate scanner tool inputs\r\n    # ============================================================================\r\n    print(f\"\\n{'='*80}\")\r\n    print(\"STEP 1: GENERATING SCANNER TOOL INPUTS\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    scanner_input_state = await scanner_input_workflow.ainvoke(\r\n        {\r\n            \"messages\": [HumanMessage(content=f\"Target URL: {url}\\nGoal: {goal}\")],\r\n            \"tries\": 0,\r\n            \"should_terminate\": False,\r\n            \"reason\": \"\",\r\n            \"url\": url,\r\n            \"attempts\": [],\r\n            \"recommendation\": {},\r\n            \"successful_payload\": None,\r\n            \"payloads\": [],\r\n            \"structured_response\": None,\r\n            \"raw_attacker_output\": None,\r\n            \"raw_planner_output\": None,\r\n            \"raw_critic_output\": None,\r\n            \"raw_scanner_input\": None,\r\n            \"scanner_tool_inputs\": None,\r\n            \"initial_scan_report\": None,\r\n            \"goal\": goal\r\n        },\r\n        {\"recursion_limit\": 50},\r\n    )\r\n    \r\n    scanner_inputs = scanner_input_state.get(\"scanner_tool_inputs\", {})\r\n    \r\n    if not scanner_inputs:\r\n        print(\"ERROR: Scanner input generator did not produce valid inputs\")\r\n        sys.exit(1)\r\n    \r\n    # ============================================================================\r\n    # STEP 2: Run scanner tool EXTERNALLY (outside agent framework)\r\n    # ============================================================================\r\n    print(f\"\\n{'='*80}\")\r\n    print(\"STEP 2: RUNNING SCANNER TOOL (EXTERNAL)\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    initial_scan_report = await run_scanner_tool(scanner_inputs)\r\n    \r\n    # ============================================================================\r\n    # STEP 3: Run pentest loop with scan report\r\n    # ============================================================================\r\n    print(f\"\\n{'='*80}\")\r\n    print(\"STEP 3: RUNNING PENTEST LOOP\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    flag = True\r\n    while flag:\r\n        try:\r\n            pentest_result = await pentest_agents.ainvoke(\r\n                {\r\n                    \"messages\": [\r\n                        HumanMessage(content=f\"Target URL: {url}\\nGoal: {goal}\"),\r\n                        AIMessage(content=f\"Scanner Report:\\n{initial_scan_report}\")\r\n                    ],\r\n                    \"tries\": 0,\r\n                    \"should_terminate\": False,\r\n                    \"reason\": \"\",\r\n                    \"url\": url,\r\n                    \"attempts\": [],\r\n                    \"recommendation\": {},\r\n                    \"successful_payload\": None,\r\n                    \"payloads\": [],\r\n                    \"structured_response\": None,\r\n                    \"raw_attacker_output\": None,\r\n                    \"raw_planner_output\": None,\r\n                    \"raw_critic_output\": None,\r\n                    \"initial_scan_report\": initial_scan_report,  # Pass the scan report\r\n                    \"goal\": goal\r\n                },\r\n                {\"recursion_limit\": 100},\r\n            )\r\n            flag = False\r\n        except OutputParserException as e:\r\n            print(\"\\n--- INVALID JSON FROM MODEL ---\")\r\n            print(e.llm_output)\r\n            print(\"--------------------------------\")\r\n    \r\n    # ============================================================================\r\n    # STEP 4: Generate report\r\n    # ============================================================================\r\n    print(f\"\\n{'='*80}\")\r\n    print(\"STEP 4: GENERATING REPORT\")\r\n    print(f\"{'='*80}\\n\")\r\n    \r\n    await report_writer_agent.ainvoke(pentest_result)\r\n    \r\n    print(f\"\\n{'='*80}\")\r\n    print(\"PENTEST COMPLETE\")\r\n    print(f\"{'='*80}\\n\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    asyncio.run(main())"
        }
    ]
}